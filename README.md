# ğŸ” Competitor Intelligence & Market Gap Finder

> AI-powered multi-agent system that transforms competitor reviews into ranked product opportunities.

---

## ğŸ§  What It Does

| Agent | Role | Output |
|-------|------|--------|
| **ScraperAgent** | Collects reviews from G2, Trustpilot, App Store, or mock | List of raw reviews |
| **FeatureExtractionAgent** | NLP enrichment + K-Means clustering | Enriched reviews + cluster themes |
| **GapDetectionAgent** | Identifies underserved clusters | Gap severity scores |
| **OpportunityScoringAgent** | Ranks opportunities by weighted model | Final scored + ranked gaps |

**Core Formula:**
```
Score_k = Î±Â·Q(Demand_k) âˆ’ Î²Â·Q(Competition_k) + Î³Â·Q(NegSentiment_k)
FinalScore_k = Confidence_k Ã— Score_k
```

Default weights: Î±=0.5, Î²=0.3, Î³=0.2

---

## ğŸš€ Quick Start

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Run demo (mock data)
```bash
python run.py --mode demo
```

### 3. Start Dashboard (Streamlit)
```bash
python run.py --mode dashboard
# â†’ http://localhost:8501
```

### 4. Start API (FastAPI)
```bash
python run.py --mode api
# â†’ http://localhost:8000/docs
```

### 5. Run with Docker
```bash
docker-compose up
```

---

## ğŸ“ Project Structure

```
competitor_intelligence/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base.py            # Abstract Agent + Orchestrator
â”‚   â”œâ”€â”€ scraper.py         # Review Scraper Agent
â”‚   â”œâ”€â”€ extractor.py       # Feature Extraction Agent (NLP + Clustering)
â”‚   â”œâ”€â”€ gap_detector.py    # Gap Detection Agent
â”‚   â””â”€â”€ scorer.py         # Opportunity Scoring Agent
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py            # FastAPI app entry point
â”‚   â”œâ”€â”€ routes.py          # API route handlers
â”‚   â””â”€â”€ schemas.py         # Pydantic request/response models
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py             # Streamlit dashboard
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ models.py          # SQLAlchemy ORM models
â”‚   â””â”€â”€ database.py        # DB session management
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py        # Centralized configuration
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py   # Pytest test suite
â”œâ”€â”€ run.py                 # CLI runner
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/pipeline/run` | Run full pipeline |
| `GET` | `/api/v1/opportunities` | Get ranked opportunities |
| `GET` | `/api/v1/opportunities/{id}` | Get single cluster detail |
| `GET` | `/api/v1/opportunities/{id}/evidence` | Get review evidence |
| `GET` | `/api/v1/score/weights` | Get current weights |
| `POST` | `/api/v1/score/weights` | Update Î±, Î², Î³ |
| `GET` | `/api/v1/summary` | Pipeline summary |
| `GET` | `/api/v1/health` | Health check |

### Example API call:
```bash
curl -X POST http://localhost:8000/api/v1/pipeline/run \
  -H "Content-Type: application/json" \
  -d '{
    "targets": [
      {"url": "https://example.com", "source_type": "mock",
       "product_name": "ProductA", "competitor_name": "CompA", "max_reviews": 200}
    ],
    "alpha": 0.5, "beta": 0.3, "gamma": 0.2
  }'
```

---

## ğŸ“Š Dashboard Sections

1. **KPI Cards** â€” Reviews analyzed, clusters found, market gaps identified
2. **Top Opportunity Card** â€” Gauge chart + recommendation
3. **Opportunity Ranking Table** â€” All clusters ranked by score
4. **Cluster Map** â€” Complaint Rate vs Competition Density scatter
5. **Complaint Heatmap** â€” Per-cluster complaint bars
6. **Score Breakdown** â€” Stacked bar showing Î±Â·Demand âˆ’ Î²Â·Competition + Î³Â·Sentiment
7. **Feature Gap Explorer** â€” Drill-down with evidence + competitor coverage

---

## âš™ï¸ Configuration

All settings in `config/settings.py` or via `.env`:

| Key | Default | Description |
|-----|---------|-------------|
| `ALPHA` | `0.5` | Demand weight |
| `BETA` | `0.3` | Competition weight |
| `GAMMA` | `0.2` | Sentiment weight |
| `COMPLAINT_RATE_THRESHOLD` | `0.30` | Min complaint rate for gap |
| `COMPETITION_DENSITY_THRESHOLD` | `0.20` | Max coverage for gap |
| `EMBEDDING_MODEL` | `all-MiniLM-L6-v2` | Sentence transformer model |
| `MAX_CLUSTERS` | `20` | Max K for clustering |

---

## ğŸ§ª Run Tests
```bash
python -m pytest tests/ -v
```

---

## â˜ï¸ Deploying to AWS Lambda

The app uses **sentence-transformers** and **scikit-learn**, so the full dependency set is ~7.5 GB. Lambdaâ€™s **500 MB limit** applies to **zip** deployments and to **runtime dependency installation**. You must deploy as a **Lambda container image** (up to **10 GB**) â€” do not use zip or â€œInstall dependencies at runtime.â€

### Fix the â€œ500 MBâ€ error

Use **only** one of these; anything else (zip upload, â€œBuild from sourceâ€, â€œInstall dependencies at runtimeâ€, or a pipeline that packages code as zip) will hit the limit:

| âœ… Use | âŒ Do not use |
|--------|----------------|
| **GitHub Action** below (container image) | Lambda â€œCreate functionâ€ â†’ â€œBuild from sourceâ€ / â€œDeploy from GitHubâ€ (zip) |
| **SAM**: `sam build` then `sam deploy` | Zip upload or â€œruntime dependency installationâ€ |
| **Docker** build + push to ECR + create Lambda from image | Any tool that deploys a .zip of your code + deps |

### Deploy with GitHub Actions (container image)

1. In the repo: **Settings â†’ Secrets and variables â†’ Actions**. Add:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
2. Optional: **Variables** â†’ `SAM_STACK_NAME` (e.g. `lead-scoring-api`), or the workflow uses `lead-scoring-api`.
3. Push to `main` or run **Actions â†’ â€œDeploy Lambda (container image)â€ â†’ Run workflow**.

The workflow runs `sam build` (builds the image from `Dockerfile.lambda`) and `sam deploy` with `--resolve-image-repos`, so the function uses the container image and 10 GB ephemeral storage.

### Deploy with AWS SAM (local)

The repo includes a SAM template that builds and deploys the API as a **container image** with 10 GB ephemeral storage.

1. **Install** [AWS SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html) and ensure **Docker** is running.

2. **Build** (builds the Lambda container image from `Dockerfile.lambda`):
   ```bash
   sam build
   ```

3. **Deploy** (first time use `--guided` to set stack name, region, etc.):
   ```bash
   sam deploy --guided
   ```
   Then for later updates:
   ```bash
   sam deploy
   ```

4. After deploy, the **API URL** is in the stack outputs (`LeadScoringApiUrl`). Use it like:
   ```text
   https://<id>.lambda-url.<region>.on.aws/
   https://<id>.lambda-url.<region>.on.aws/api/v1/health
   https://<id>.lambda-url.<region>.on.aws/docs
   ```

The template sets: **PackageType: Image**, **EphemeralStorage: 10240 MB**, **MemorySize: 4096**, **Timeout: 900**.

### Deploy with Docker + ECR (manual)

1. Build: `docker build -f Dockerfile.lambda -t lead-scoring-api .`
2. Tag and push the image to Amazon ECR in your region.
3. Create (or update) a Lambda function from that image. Set **Handler** to `api.lambda_handler.handler`, **Ephemeral storage** to 10 GB, and add a **Function URL** if needed.

### Why not zip?

Zip (or â€œruntime dependency installationâ€) is limited to 500 MB. This appâ€™s dependencies are ~7.5 GB, so deployment must use a **container image**.

**If you still see â€œTotal dependency size exceeds Lambda ephemeral storage limit (500 MB)â€:** your deployment is using a **zip** or **runtime dependency installation**, not a container image. Switch to **SAM** (`sam build` then `sam deploy`) so the templateâ€™s `PackageType: Image` and `Dockerfile.lambda` are used, or deploy the Docker image to Lambda manually. Do not use â€œDeploy from zipâ€ or options that install dependencies at runtime.

---

## ğŸ—ºï¸ Architecture

```
List[ScrapeTarget]
       â”‚
       â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ ScraperAgentâ”‚  â† HTML, RSS, Mock
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚ List[RawReview]
        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ FeatureExtractionAgentâ”‚  â† Sentiment, Embeddings, K-Means
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ ExtractorOutput
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ GapDetectionAgent â”‚  â† Coverage density, Gap severity
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ GapDetectionOutput
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ OpportunityScoringAgentâ”‚  â† Weighted score + confidence
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ ScoringOutput
              â–¼
     API / Dashboard
```
